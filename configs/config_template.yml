exp_name: "mmlu-standard-zero-shot"
# data paths
task_input_path: "./mmlu/mmlu_validation-batched_4.json"
task_desc_path: "./mmlu/mmlu-task_description_formatted.json"
log_path: "./log/mmlu"
# experiment settings
inference_mode: "stream"
exemplars_mode: "standard"
num_demos: 0
use_cot: False
diverse_exemplars: False
label_method: "self"
# sizes
batch_size: 1
test_sample_size: "full"
# model hparams
model: "text-davinci-003"
max_tokens: 1024
temperature: 0.0 # temperature when performing inference
demo_temperature: 0.0 # temperature when generating pseudo-demos (only used when exemplars_mode == "self-icl")
top_p: 1.0